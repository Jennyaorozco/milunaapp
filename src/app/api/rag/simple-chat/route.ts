// app/api/rag/simple-chat/route.ts - VERSIÃ“N CORREGIDA CON TYPESCRIPT FIX
import { NextRequest, NextResponse } from "next/server";
import { GoogleGenerativeAI } from "@google/generative-ai";

// Inicializar Gemini
const genAI = new GoogleGenerativeAI(process.env.GOOGLE_GEMINI_API_KEY || "");

// Variable para cachear el modelo que funciona
let workingModel: string | null = null;

// âœ… FUNCIÃ“N DETECT WORKING MODEL - CORREGIDA
async function detectWorkingModel(): Promise<string> {
  if (workingModel) {
    return workingModel;
  }

  // MODELOS ACTUALES DE GEMINI (Octubre 2024)
  const testModels = [
    "gemini-2.0-flash-exp",
    "gemini-1.5-flash",
    "gemini-1.5-pro", 
    "gemini-1.0-pro",
    "gemini-pro",
    "models/gemini-pro"
  ];

  for (const modelName of testModels) {
    try {
      console.log(`ğŸ” Probando modelo: ${modelName}`);
      const model = genAI.getGenerativeModel({ 
        model: modelName,
        generationConfig: { maxOutputTokens: 10 }
      });
      
      const result = await model.generateContent("Hola");
      await result.response;
      
      workingModel = modelName;
      console.log(`âœ… Modelo encontrado: ${workingModel}`);
      return workingModel;
      
    } catch (error) {
      // âœ… CORRECCIÃ“N: Verificar tipo del error
      const errorMessage = error instanceof Error ? error.message : String(error);
      console.log(`âŒ ${modelName} no funciona:`, errorMessage);
      continue;
    }
  }

  throw new Error("No se encontrÃ³ ningÃºn modelo de Gemini funcionando. Modelos probados: " + testModels.join(', '));
}

// [Mantener toda la base de conocimiento igual...]
const localKnowledgeBase = {
  greetings: [
    "Â¡Hola! Soy Luna, tu asistente personal ğŸŒ™ Â¿En quÃ© puedo ayudarte hoy?",
    "Â¡Hola! Me da mucho gusto verte por aquÃ­ ğŸ‘‹",
    "Â¡Buen dÃ­a! Soy Luna, tu asistente. Estoy aquÃ­ para lo que necesites",
    "Â¡Hola! ğŸŒŸ Â¿CÃ³mo estÃ¡s? Soy Luna, lista para ayudarte"
  ],
  
  capabilities: [
    `Puedo ayudarte con:

â€¢ Respuestas a preguntas generales usando inteligencia artificial
â€¢ InformaciÃ³n sobre esta aplicaciÃ³n (Miluna)
â€¢ ConversaciÃ³n natural y amigable
â€¢ AnÃ¡lisis inteligente de documentos PDF (prÃ³ximamente)
â€¢ Asistencia personalizada 24/7

Â¿QuÃ© te gustarÃ­a saber?`,

    `Mis funciones incluyen:

âœ¨ Chat inteligente con Gemini AI
ğŸ“Š PrÃ³ximo anÃ¡lisis de documentos PDF
ğŸ” BÃºsqueda de informaciÃ³n en tiempo real
ğŸ’¬ Soporte conversacional avanzado
ğŸ¯ Respuestas personalizadas y contextuales

Â¡PregÃºntame lo que quieras!`
  ],
  
  documents: [
    `ğŸ“š **FunciÃ³n de Documentos PDF** (PrÃ³ximamente)

Estoy desarrollando la capacidad de:
â€¢ Leer y analizar tus archivos PDF
â€¢ Responder preguntas especÃ­ficas sobre el contenido
â€¢ Extraer informaciÃ³n importante automÃ¡ticamente
â€¢ Resumir documentos largos de manera inteligente

Â¡Muy pronto podrÃ¡s subir tus documentos y hacerme preguntas especÃ­ficas sobre ellos!`,

    `El anÃ¡lisis inteligente de PDFs estÃ¡ en desarrollo avanzado. PodrÃ¡s:
- Subir documentos PDF directamente
- Hacer preguntas especÃ­ficas sobre el contenido
- Obtener resÃºmenes automÃ¡ticos y extractos
- Encontrar informaciÃ³n especÃ­fica rÃ¡pidamente

Es una de las funciones mÃ¡s emocionantes que viene ğŸ˜Š`
  ],
  
  app: [
    `**Miluna** es tu aplicaciÃ³n personal todo-en-uno ğŸŒ™

Funciones principales:
â€¢ Asistente inteligente con IA (yo misma ğŸ˜Š)
â€¢ GestiÃ³n de recordatorios y tareas
â€¢ Herramientas de productividad integradas
â€¢ Interfaz amigable y personalizable
â€¢ Soporte con Google Gemini AI

Â¡Estoy aquÃ­ para hacer tu vida mÃ¡s fÃ¡cil y organizada!`,

    `**Miluna App** - Tu compaÃ±era digital inteligente

Soy Luna, el asistente con IA integrado en Miluna. Esta aplicaciÃ³n estÃ¡ diseÃ±ada para:
- Ayudarte en tu dÃ­a a dÃ­a con tecnologÃ­a avanzada
- Mantenerte organizado de manera eficiente
- Proporcionar asistencia inmediata con IA
- Crecer constantemente con nuevas funciones

Â¿QuÃ© te parece la aplicaciÃ³n hasta ahora?`
  ]
};

// Respuestas especÃ­ficas para preguntas comunes
const specificResponses: { [key: string]: string } = {
  "quÃ© es miluna": `**Miluna** es tu aplicaciÃ³n personal todo-en-uno ğŸŒ™

Desarrollada para ser tu compaÃ±era digital inteligente, ofreciendo:
â€¢ Asistente con IA (Â¡yo! - potenciado por Google Gemini)
â€¢ GestiÃ³n inteligente de recordatorios
â€¢ Herramientas de productividad avanzadas
â€¢ Interfaz intuitiva y visualmente atractiva

Â¿QuÃ© funciÃ³n te gustarÃ­a explorar primero?`,

  "quiÃ©n eres": `Soy **Luna** ğŸŒ™, tu asistente personal inteligente integrado en Miluna.

Estoy potenciada por **Google Gemini AI** y mi propÃ³sito es:
- Hacer tu experiencia mÃ¡s fÃ¡cil, rÃ¡pida y agradable
- Responder tus preguntas de manera inteligente y Ãºtil
- Aprender de nuestras conversaciones para mejorar
- Evolucionar constantemente con nuevas capacidades

Â¡Es un placer conocerte! ğŸ˜Š`,

  "cÃ³mo estÃ¡s": `Â¡Estoy muy bien, gracias por preguntar! ğŸ˜Š 

Hoy estoy especialmente contenta porque funciono con Google Gemini, lo que me permite ayudarte de manera mÃ¡s inteligente.

Â¿Y tÃº, cÃ³mo estÃ¡s hoy?`,

  "quÃ© hora es": `âŒš Son las ${new Date().toLocaleTimeString('es-ES', { hour: '2-digit', minute: '2-digit' })}.

Â¿Hay algo especÃ­fico en lo que te pueda ayudar en este momento?`,

  "gracias": `Â¡De nada! ğŸ˜Š 

Es un verdadero placer ayudarte. No dudes en preguntarme cualquier cosa cuando lo necesites - estoy aquÃ­ las 24 horas.

Â¿Hay algo mÃ¡s en lo que pueda asistirte?`,

  "adiÃ³s": `Â¡Hasta luego! ğŸ‘‹ 

Fue un gusto conversar contigo. Vuelve cuando necesites ayuda, siempre estarÃ© aquÃ­.

Â¡Que tengas un excelente dÃ­a! ğŸŒŸ`,

  "hola luna": `Â¡Hola! ğŸŒ™ 

Me da mucho gusto que me llames por mi nombre. Soy Luna, tu asistente personal potenciado por Google Gemini.

Â¿En quÃ© puedo ayudarte hoy?`
};

// FunciÃ³n para analizar la intenciÃ³n del mensaje
function analyzeIntent(message: string): string {
  const lowerMessage = message.toLowerCase();
  
  if (/(hola|hi|hey|buenas|saludos|hola luna)/i.test(lowerMessage)) {
    return 'greeting';
  }
  
  if (/(quÃ© puedes|quÃ© sabes|funciones|capacidades|para quÃ© sirves|quÃ© haces)/i.test(lowerMessage)) {
    return 'capabilities';
  }
  
  if (/(pdf|documento|archivo|leer|analizar|subir)/i.test(lowerMessage)) {
    return 'documents';
  }
  
  if (/(app|aplicaciÃ³n|miluna|quÃ© es esto|para quÃ© es)/i.test(lowerMessage)) {
    return 'app';
  }
  
  return 'general';
}

// FunciÃ³n para seleccionar respuesta aleatoria
function getRandomResponse(responses: string[]): string {
  return responses[Math.floor(Math.random() * responses.length)];
}

// FunciÃ³n para generar respuesta local
function generateLocalResponse(message: string): string {
  const lowerMessage = message.toLowerCase().trim();
  
  // Buscar respuesta especÃ­fica primero
  for (const [key, response] of Object.entries(specificResponses)) {
    if (lowerMessage.includes(key)) {
      return response;
    }
  }
  
  // Si no hay respuesta especÃ­fica, analizar la intenciÃ³n
  const intent = analyzeIntent(message);
  
  switch (intent) {
    case 'greeting':
      return getRandomResponse(localKnowledgeBase.greetings);
    case 'capabilities':
      return getRandomResponse(localKnowledgeBase.capabilities);
    case 'documents':
      return getRandomResponse(localKnowledgeBase.documents);
    case 'app':
      return getRandomResponse(localKnowledgeBase.app);
    default:
      return `Â¡Interesante pregunta! ğŸŒŸ

Como asistente potenciado por IA, normalmente podrÃ­a darte una respuesta mÃ¡s especÃ­fica, pero estoy teniendo un problema temporal de conexiÃ³n.

Mientras se soluciona, Â¿hay algo especÃ­fico sobre Miluna o mis funciones en lo que te pueda ayudar?`;
  }
}

// âœ… FUNCIÃ“N CORREGIDA PARA GEMINI - CON MANEJO DE ERRORES TYPESCRIPT
async function callGemini(message: string): Promise<string> {
  console.log("ğŸ”‘ Intentando con Google Gemini...");
  
  if (!process.env.GOOGLE_GEMINI_API_KEY) {
    throw new Error("Google Gemini API key no configurada");
  }

  try {
    // Detectar el modelo que funciona
    const modelName = await detectWorkingModel();
    console.log(`ğŸš€ Usando modelo: ${modelName}`);

    const model = genAI.getGenerativeModel({ 
      model: modelName,
      generationConfig: {
        temperature: 0.7,
        topK: 40,
        topP: 0.95,
        maxOutputTokens: 1024,
      }
    });

    const prompt = `Eres Luna, un asistente amigable y Ãºtil integrado en la aplicaciÃ³n Miluna.

CONTEXTO:
- Eres un asistente de chat dentro de Miluna
- La aplicaciÃ³n tiene funciones de recordatorios, gestiÃ³n y herramientas
- PrÃ³ximamente tendrÃ¡s capacidad de anÃ¡lisis de PDFs
- MantÃ©n un tono cÃ¡lido, amigable y profesional
- EstÃ¡s potenciado por Google Gemini

INSTRUCCIONES:
- Responde como Luna, el asistente
- SÃ© concisa pero amigable (mÃ¡ximo 3 pÃ¡rrafos)
- No menciones que eres un modelo de IA, solo di que usas tecnologÃ­a avanzada
- Responde en el mismo idioma del usuario
- Si preguntan sobre PDFs, menciona amablemente que viene pronto
- MantÃ©n la conversaciÃ³n natural y humana
- Usa emojis apropiados ocasionalmente ğŸŒ™âœ¨

PREGUNTA DEL USUARIO: ${message}

RESPUESTA:`;

    const result = await model.generateContent(prompt);
    const response = await result.response;
    const text = response.text();

    return text;

  } catch (error) {
    // âœ… CORRECCIÃ“N: Manejo seguro del tipo unknown
    const errorMessage = error instanceof Error ? error.message : String(error);
    console.error("Error en Gemini:", error);
    throw new Error(`Gemini error: ${errorMessage}`);
  }
}

export async function POST(request: NextRequest) {
  try {
    const { message } = await request.json();

    console.log("ğŸ“¨ Mensaje recibido:", message);

    if (!message || message.trim() === '') {
      return NextResponse.json({
        success: false,
        error: "El mensaje estÃ¡ vacÃ­o"
      });
    }

    let responseText = '';
    let responseType = 'local';
    let geminiError = null;

    // INTENTAR CON GEMINI PRIMERO (si hay API key)
    if (process.env.GOOGLE_GEMINI_API_KEY) {
      try {
        responseText = await callGemini(message);
        responseType = 'gemini';
        console.log("âœ… Respuesta de Gemini exitosa");
      } catch (error) {
        // âœ… CORRECCIÃ“N: Manejo seguro del tipo unknown
        geminiError = error instanceof Error ? error.message : String(error);
        console.log("ğŸ”„ Gemini fallÃ³, usando modo local. Error:", geminiError);
        
        // Intentar con OpenAI como respaldo si estÃ¡ configurado
        if (process.env.OPENAI_API_KEY && process.env.OPENAI_API_KEY.startsWith('sk-')) {
          try {
            console.log("ğŸ”„ Intentando con OpenAI como respaldo...");
            const openaiResponse = await fetch('https://api.openai.com/v1/chat/completions', {
              method: 'POST',
              headers: {
                'Content-Type': 'application/json',
                'Authorization': `Bearer ${process.env.OPENAI_API_KEY}`
              },
              body: JSON.stringify({
                model: 'gpt-3.5-turbo',
                messages: [
                  {
                    role: 'system',
                    content: "Eres Luna, un asistente amigable. Responde de manera concisa y Ãºtil."
                  },
                  {
                    role: 'user',
                    content: message
                  }
                ],
                max_tokens: 300,
                temperature: 0.7
              })
            });

            if (openaiResponse.ok) {
              const data = await openaiResponse.json();
              responseText = data.choices[0].message.content;
              responseType = 'openai';
              console.log("âœ… Respuesta de OpenAI exitosa (respaldo)");
            } else {
              throw new Error("OpenAI tambiÃ©n fallÃ³");
            }
          } catch (openaiError) {
            // âœ… CORRECCIÃ“N: Manejo seguro del tipo unknown
            const openaiErrorMessage = openaiError instanceof Error ? openaiError.message : String(openaiError);
            console.log("âŒ OpenAI tambiÃ©n fallÃ³:", openaiErrorMessage);
          }
        }
      }
    } else {
      console.log("ğŸ”„ No hay API key de Gemini, usando modo local");
    }

    // SI GEMINI FALLÃ“ O NO HAY API KEY, USAR MODO LOCAL
    if (!responseText) {
      responseText = generateLocalResponse(message);
      console.log("âœ… Respuesta local generada");
    }

    return NextResponse.json({
      success: true,
      response: responseText,
      sources: [],
      type: responseType,
      gemini_status: responseType === 'gemini' ? 'active' : 'inactive',
      gemini_error: geminiError,
      gemini_model: workingModel || 'not_detected'
    });

  } catch (error) {
    // âœ… CORRECCIÃ“N: Manejo seguro del tipo unknown
    const errorMessage = error instanceof Error ? error.message : String(error);
    console.error('âŒ Error general en el chat:', error);
    
    // Fallback ultra-resiliente
    const fallbackResponse = `Â¡Hola! Soy Luna ğŸŒ™

Parece que hay un pequeÃ±o problema tÃ©cnico temporal con mis sistemas de IA, pero estoy aquÃ­ para ayudarte con mis respuestas locales.

Â¿En quÃ© puedo asistirte hoy?`;

    return NextResponse.json({
      success: true,
      response: fallbackResponse,
      sources: [],
      type: "error_fallback"
    });
  }
}

// âœ… Endpoint GET CORREGIDO CON MANEJO DE ERRORES TYPESCRIPT
export async function GET() {
  const hasGeminiKey = !!process.env.GOOGLE_GEMINI_API_KEY;
  const hasOpenAIKey = !!(process.env.OPENAI_API_KEY && process.env.OPENAI_API_KEY.startsWith('sk-'));
  
  let geminiTest: { 
    status: string; 
    error: string | null; 
    model: string | null 
  } = {
    status: 'not_tested',
    error: null,
    model: null
  };

  // Probar Gemini si hay key
  if (hasGeminiKey) {
    try {
      const modelName = await detectWorkingModel();
      geminiTest.status = 'working';
      geminiTest.model = modelName;
    } catch (error) {
      // âœ… CORRECCIÃ“N: Manejo seguro del tipo unknown
      geminiTest.status = 'error';
      geminiTest.error = error instanceof Error ? error.message : String(error);
    }
  }

  return NextResponse.json({
    status: "active",
    message: "Chat endpoint funcionando",
    timestamp: new Date().toISOString(),
    ai_providers: {
      gemini: {
        configured: hasGeminiKey,
        status: geminiTest.status,
        model: geminiTest.model,
        error: geminiTest.error
      },
      openai: {
        configured: hasOpenAIKey,
        status: hasOpenAIKey ? 'not_tested' : 'not_configured',
        error: null
      },
      local: {
        status: "active"
      }
    },
    mode: hasGeminiKey && geminiTest.status === 'working' ? "gemini_primary" : hasOpenAIKey ? "openai_primary" : "local_only",
    features: [
      "Google Gemini AI (gratuito)",
      "OpenAI GPT (respaldo, si estÃ¡ configurado)",
      "Modo local inteligente",
      "DetecciÃ³n automÃ¡tica de modelos",
      "Sistema de fallback automÃ¡tico"
    ]
  });
}
